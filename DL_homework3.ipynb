{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57d94b2a-f477-410d-a10a-260e4b680138",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/gauravp/.local/lib/python3.11/site-packages (4.46.2)\n",
      "Requirement already satisfied: datasets in /home/gauravp/.local/lib/python3.11/site-packages (3.1.0)\n",
      "Requirement already satisfied: filelock in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/gauravp/.local/lib/python3.11/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in /home/gauravp/.local/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/gauravp/.local/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/gauravp/.local/lib/python3.11/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/gauravp/.local/lib/python3.11/site-packages (from transformers) (4.67.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/gauravp/.local/lib/python3.11/site-packages (from datasets) (18.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: xxhash in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]<=2024.9.0,>=2023.1.0 in /home/gauravp/.local/lib/python3.11/site-packages (from datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/gauravp/.local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: evaluate==0.3.0 in /home/gauravp/.local/lib/python3.11/site-packages (0.3.0)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /home/gauravp/.local/lib/python3.11/site-packages (from evaluate==0.3.0) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from evaluate==0.3.0) (1.24.3)\n",
      "Requirement already satisfied: dill in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from evaluate==0.3.0) (0.3.6)\n",
      "Requirement already satisfied: pandas in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from evaluate==0.3.0) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/gauravp/.local/lib/python3.11/site-packages (from evaluate==0.3.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/gauravp/.local/lib/python3.11/site-packages (from evaluate==0.3.0) (4.67.0)\n",
      "Requirement already satisfied: xxhash in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from evaluate==0.3.0) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from evaluate==0.3.0) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/gauravp/.local/lib/python3.11/site-packages (from evaluate==0.3.0) (2024.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /home/gauravp/.local/lib/python3.11/site-packages (from evaluate==0.3.0) (0.26.2)\n",
      "Requirement already satisfied: packaging in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from evaluate==0.3.0) (23.1)\n",
      "Requirement already satisfied: responses<0.19 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from evaluate==0.3.0) (0.13.3)\n",
      "Requirement already satisfied: filelock in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate==0.3.0) (3.9.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/gauravp/.local/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate==0.3.0) (18.0.0)\n",
      "Requirement already satisfied: aiohttp in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate==0.3.0) (3.8.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate==0.3.0) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/gauravp/.local/lib/python3.11/site-packages (from huggingface-hub>=0.7.0->evaluate==0.3.0) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from requests>=2.19.0->evaluate==0.3.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from requests>=2.19.0->evaluate==0.3.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from requests>=2.19.0->evaluate==0.3.0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from requests>=2.19.0->evaluate==0.3.0) (2023.7.22)\n",
      "Requirement already satisfied: six in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from responses<0.19->evaluate==0.3.0) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from pandas->evaluate==0.3.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from pandas->evaluate==0.3.0) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from pandas->evaluate==0.3.0) (2023.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.3.0) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.3.0) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.3.0) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.3.0) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.3.0) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.3.0) (1.2.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: jiwer in /home/gauravp/.local/lib/python3.11/site-packages (3.0.5)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.3 in /home/gauravp/.local/lib/python3.11/site-packages (from jiwer) (8.1.7)\n",
      "Requirement already satisfied: rapidfuzz<4,>=3 in /home/gauravp/.local/lib/python3.11/site-packages (from jiwer) (3.10.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers datasets\n",
    "!pip install evaluate==0.3.0\n",
    "!pip install jiwer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30936d64-e040-436b-95a4-aeb41539aa55",
   "metadata": {},
   "source": [
    "#### Loading necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6125f97-adc8-4a5f-b09e-866fe3274e6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import transformers\n",
    "from transformers import BertModel, BertTokenizerFast, AdamW\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1374299-f4b8-4e8c-beb6-bf264c22ae55",
   "metadata": {},
   "source": [
    "#### Retrieving data from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63b34d10-f031-4046-992f-6fdff5938b7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data(path): \n",
    "    with open(path, 'rb') as f:\n",
    "        raw_data = json.load(f)\n",
    "    contexts = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "    num_q = 0\n",
    "    num_pos = 0\n",
    "    num_imp = 0\n",
    "\n",
    "    for group in raw_data['data']:\n",
    "        for paragraph in group['paragraphs']:\n",
    "            context = paragraph['context']\n",
    "            for qa in paragraph['qas']:\n",
    "                question = qa['question']\n",
    "                num_q  = num_q  +1\n",
    "                for answer in qa['answers']:\n",
    "                    contexts.append(context.lower())\n",
    "                    questions.append(question.lower())\n",
    "                    answers.append(answer)\n",
    "    return num_q, num_pos, num_imp, contexts, questions, answers\n",
    "\n",
    "\n",
    "num_q, num_pos, num_imp, train_contexts, train_questions, train_answers = get_data('spoken_train-v1.1.json')\n",
    "num_questions  = num_q\n",
    "num_posible = num_pos\n",
    "num_imposible  = num_imp\n",
    "\n",
    "\n",
    "num_q, num_pos, num_imp, valid_contexts, valid_questions, valid_answers = get_data('spoken_test-v1.1.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e352d84c-db3a-4755-b9ee-cee8e4053f24",
   "metadata": {},
   "source": [
    "#### Adding a field to label text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b19ce32-f6d1-46dd-ae5d-b7195e49986f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_answer_end(answers, contexts):\n",
    "    for answer, context in zip(answers, contexts):\n",
    "        answer['text'] = answer['text'].lower()\n",
    "        answer['answer_end'] = answer['answer_start'] + len(answer['text'])\n",
    "\n",
    "add_answer_end(train_answers, train_contexts)\n",
    "add_answer_end(valid_answers, valid_contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914cfe83-3cba-49c7-9c7a-a4181c4ea5cf",
   "metadata": {},
   "source": [
    "#### Splitting text into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83625053-cf5b-4640-9eee-e1042835b72a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 512\n",
    "MODEL_PATH = \"bert-base-uncased\"\n",
    "\n",
    "doc_stride = 128\n",
    "tokenizerFast = BertTokenizerFast.from_pretrained(MODEL_PATH)\n",
    "pad_on_right = tokenizerFast.padding_side == \"right\"\n",
    "train_contexts_trunc=[]\n",
    "\n",
    "for i in range(len(train_contexts)):\n",
    "    if(len(train_contexts[i])>512):\n",
    "        answer_start=train_answers[i]['answer_start']\n",
    "        answer_end=train_answers[i]['answer_start']+len(train_answers[i]['text'])\n",
    "        mid=(answer_start+answer_end)//2\n",
    "        para_start=max(0,min(mid - MAX_LENGTH//2,len(train_contexts[i])-MAX_LENGTH))\n",
    "        para_end = para_start + MAX_LENGTH \n",
    "        train_contexts_trunc.append(train_contexts[i][para_start:para_end])\n",
    "        train_answers[i]['answer_start']=((512/2)-len(train_answers[i])//2)\n",
    "    else:\n",
    "        train_contexts_trunc.append(train_contexts[i])\n",
    "\n",
    "train_encodings_fast = tokenizerFast(train_questions, train_contexts_trunc,  max_length = MAX_LENGTH,truncation=True,\n",
    "        stride=doc_stride,\n",
    "        padding=True)\n",
    "valid_encodings_fast = tokenizerFast(valid_questions,valid_contexts,  max_length = MAX_LENGTH, truncation=True,stride=doc_stride,\n",
    "        padding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aee0ca1-d442-4682-973c-988d6a4ff4d6",
   "metadata": {},
   "source": [
    "#### Locating the start and end of the answer within the paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2539a116-f00e-443a-b5f4-b2306f6a09f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ret_Answer_start_and_end_train(idx):\n",
    "    ret_start = 0\n",
    "    ret_end = 0\n",
    "    answer_encoding_fast = tokenizerFast(train_answers[idx]['text'],  max_length = MAX_LENGTH, truncation=True, padding=True)\n",
    "    for a in range( len(train_encodings_fast['input_ids'][idx]) -  len(answer_encoding_fast['input_ids']) ):\n",
    "        match = True\n",
    "        for i in range(1,len(answer_encoding_fast['input_ids']) - 1):\n",
    "            if (answer_encoding_fast['input_ids'][i] != train_encodings_fast['input_ids'][idx][a + i]):\n",
    "                match = False\n",
    "                break\n",
    "            if match:\n",
    "                ret_start = a+1\n",
    "                ret_end = a+i+1\n",
    "                break\n",
    "    return(ret_start, ret_end)\n",
    "\n",
    "start_positions = []\n",
    "end_positions = []\n",
    "ctr = 0\n",
    "for h in range(len(train_encodings_fast['input_ids'])):\n",
    "    s, e = ret_Answer_start_and_end_train(h)\n",
    "    start_positions.append(s)\n",
    "    end_positions.append(e)\n",
    "    if s==0:\n",
    "        ctr = ctr + 1\n",
    "\n",
    "train_encodings_fast.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
    "valid_encodings_fast.update({'start_positions': start_positions, 'end_positions': end_positions})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9100dd-8356-4fde-8769-8c3f3787d741",
   "metadata": {},
   "source": [
    "#### Building dataset for the loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e71c2835-2177-4f93-acfa-193977932ce8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class InputDataset(Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, i):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.encodings['input_ids'][i]),\n",
    "            'token_type_ids': torch.tensor(self.encodings['token_type_ids'][i]),\n",
    "            'attention_mask': torch.tensor(self.encodings['attention_mask'][i]),\n",
    "            'start_positions': torch.tensor(self.encodings['start_positions'][i]),\n",
    "            'end_positions': torch.tensor(self.encodings['end_positions'][i])\n",
    "        }\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "    \n",
    "train_dataset = InputDataset(train_encodings_fast)\n",
    "valid_dataset = InputDataset(valid_encodings_fast)\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "valid_data_loader = DataLoader(valid_dataset, batch_size=1)\n",
    "\n",
    "bert_model = BertModel.from_pretrained(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e38f02b-29d8-462a-b897-6118f2ccd45b",
   "metadata": {},
   "source": [
    "#### Setting up the model for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5cf0d62-2ba2-4405-bb59-710825f31707",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class QAModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QAModel, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.drop_out = nn.Dropout(0.1)\n",
    "        self.l1 = nn.Linear(768 * 2, 768 * 2)\n",
    "        self.l2 = nn.Linear(768 * 2, 2)\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            self.drop_out,\n",
    "            self.l1,\n",
    "            nn.LeakyReLU(),\n",
    "            self.l2 \n",
    "        )\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        model_output = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, output_hidden_states=True)\n",
    "        hidden_states = model_output[2]\n",
    "        out = torch.cat((hidden_states[-1], hidden_states[-3]), dim=-1)\n",
    "        logits = self.linear_relu_stack(out)\n",
    "        \n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "        \n",
    "        start_logits = start_logits.squeeze(-1)\n",
    "        end_logits = end_logits.squeeze(-1)\n",
    "\n",
    "        return start_logits, end_logits\n",
    "\n",
    "model = QAModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c820489-4114-44dd-a8bd-cc424f622055",
   "metadata": {},
   "source": [
    "#### Defining loss and training methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdd346b9-0480-404d-881e-65b01b68eb05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gauravp/.local/lib/python3.11/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def focal_loss_fn(start_logits, end_logits, start_positions, end_positions, gamma):\n",
    "    smax = nn.Softmax(dim=1)\n",
    "    probs_start = smax(start_logits)\n",
    "    inv_probs_start = 1 - probs_start\n",
    "    probs_end = smax(end_logits)\n",
    "    inv_probs_end = 1 - probs_end\n",
    "    \n",
    "    lsmax = nn.LogSoftmax(dim=1)\n",
    "    log_probs_start = lsmax(start_logits)\n",
    "    log_probs_end = lsmax(end_logits)\n",
    "    \n",
    "    nll = nn.NLLLoss()\n",
    "    \n",
    "    fl_start = nll(torch.pow(inv_probs_start, gamma)* log_probs_start, start_positions)\n",
    "    fl_end = nll(torch.pow(inv_probs_end, gamma)*log_probs_end, end_positions)\n",
    "    \n",
    "    return ((fl_start + fl_end)/2)\n",
    "\n",
    "optim = AdamW(model.parameters(), lr=2e-5, weight_decay=2e-2)\n",
    "total_acc = []\n",
    "total_loss = []\n",
    "\n",
    "def train_epoch(model, dataloader, epoch):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    acc = []\n",
    "    ctr = 0\n",
    "    batch_tracker = 0\n",
    "    for batch in tqdm(dataloader, desc = 'Running Epoch '):\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "        out_start, out_end = model(input_ids=input_ids, \n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids)\n",
    "\n",
    "        loss = focal_loss_fn(out_start, out_end, start_positions, end_positions,1)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        start_pred = torch.argmax(out_start, dim=1)\n",
    "        end_pred = torch.argmax(out_end, dim=1)\n",
    "            \n",
    "        acc.append(((start_pred == start_positions).sum()/len(start_pred)).item())\n",
    "        acc.append(((end_pred == end_positions).sum()/len(end_pred)).item())\n",
    "\n",
    "        batch_tracker = batch_tracker + 1\n",
    "        if batch_tracker==250 and epoch==1:\n",
    "            total_acc.append(sum(acc)/len(acc))\n",
    "            loss_avg = sum(losses)/len(losses)\n",
    "            total_loss.append(loss_avg)\n",
    "            batch_tracker = 0\n",
    "    ret_acc = sum(acc)/len(acc)\n",
    "    ret_loss = sum(losses)/len(losses)\n",
    "    \n",
    "    num_same = (start_pred == start_positions).sum() + (end_pred == end_positions).sum()\n",
    "    precision = 1.0 * num_same / (len(start_pred) + len(end_pred))\n",
    "    recall = 1.0 * num_same / (len(start_positions) + len(end_positions))\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    \n",
    "    return (ret_acc, ret_loss, f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c466443-1113-4117-be61-4a2167ad96b6",
   "metadata": {},
   "source": [
    "#### Measuring performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5822723-1cb1-4eb2-970e-89c316d5c00d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_model(model, dataloader):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    acc = []\n",
    "    ctr = 0\n",
    "    answer_list=[]\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc = 'Running Evaluation'):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            token_type_ids = batch['token_type_ids'].to(device)\n",
    "            start_true = batch['start_positions'].to(device)\n",
    "            end_true = batch['end_positions'].to(device)\n",
    "            \n",
    "            out_start, out_end = model(input_ids=input_ids, attention_mask=attention_mask,token_type_ids=token_type_ids)\n",
    "\n",
    "            start_pred = torch.argmax(out_start)\n",
    "            end_pred = torch.argmax(out_end)\n",
    "            answer = tokenizerFast.convert_tokens_to_string(tokenizerFast.convert_ids_to_tokens(input_ids[0][start_pred:end_pred]))\n",
    "            tanswer = tokenizerFast.convert_tokens_to_string(tokenizerFast.convert_ids_to_tokens(input_ids[0][start_true[0]:end_true[0]]))\n",
    "            answer_list.append([answer,tanswer])\n",
    "\n",
    "    return answer_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe5890d-d6bd-48ed-9c63-d842d906be26",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf428088-e6a8-42ab-bf4a-c7dddc8de3b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Epoch : 100%|██████████| 2320/2320 [04:14<00:00,  9.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.46754926108787287\n",
      "Loss: 1.8026556722562888\n",
      "F1: 0.2142857313156128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Evaluation: 100%|██████████| 15875/15875 [02:34<00:00, 102.67it/s]\n",
      "Running Epoch : 100%|██████████| 2320/2320 [04:15<00:00,  9.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.667849445831159\n",
      "Loss: 0.8816307985255945\n",
      "F1: 0.785714328289032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Evaluation: 100%|██████████| 15875/15875 [02:34<00:00, 102.98it/s]\n",
      "Running Epoch : 100%|██████████| 2320/2320 [04:15<00:00,  9.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7745882081574407\n",
      "Loss: 0.5173119974804335\n",
      "F1: 0.8571429252624512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Evaluation: 100%|██████████| 15875/15875 [02:34<00:00, 102.83it/s]\n",
      "Running Epoch : 100%|██████████| 2320/2320 [05:13<00:00,  7.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8503021090195096\n",
      "Loss: 0.30536930916774696\n",
      "F1: 0.8571429252624512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Evaluation: 100%|██████████| 15875/15875 [08:57<00:00, 29.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER (base model) -  [5.461165354330709, 4.487874015748032, 3.8753385826771654, 3.861984251968504]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from evaluate import load\n",
    "\n",
    "# Load WER without DownloadConfig\n",
    "wer = load(\"wer\")\n",
    "\n",
    "EPOCHS = 3\n",
    "model.to(device)\n",
    "wer_list = []\n",
    "print('Starting training')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_acc, train_loss, train_f1 = train_epoch(model, train_data_loader, epoch+1)\n",
    "    print(f\"Accuracy: {train_acc}\")\n",
    "    print(f\"Loss: {train_loss}\")\n",
    "    print(f\"F1: {train_f1}\")\n",
    "    \n",
    "    \n",
    "    answer_list = eval_model(model, valid_data_loader)\n",
    "    pred_answers=[]\n",
    "    true_answers=[]\n",
    "    for i in range(len(answer_list)):\n",
    "        if(len(answer_list[i][0])==0):\n",
    "            answer_list[i][0]=\"$\"\n",
    "        if(len(answer_list[i][1])==0):\n",
    "            answer_list[i][1]=\"$\"\n",
    "        pred_answers.append(answer_list[i][0])\n",
    "        true_answers.append(answer_list[i][1])\n",
    "    wer_score = wer.compute(predictions=pred_answers, references=true_answers)\n",
    "    wer_list.append(wer_score)\n",
    "\n",
    "print('WER (base model) - ',wer_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea67d8e8-3cb1-41cf-a378-e21d9bb41cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
